Building an NLP Pipeline, Step-by-Step

IMP LINKS:
https://explosion.ai/blog/parsing-english-in-python
https://medium.com/@ageitgey/natural-language-processing-is-fun-9a0bff37854e
https://medium.com/@ageitgey/text-classification-is-your-new-secret-weapon-7ca4fad15788

Step 1: Sentence Segmentation
The first step in the pipeline is to break the text apart into separate sentences. 
Coding a Sentence Segmentation model can be as simple as splitting apart sentences whenever you see a punctuation mark. 
But modern NLP pipelines often use more complex techniques that work even when a document isn’t formatted cleanly.

Step 2: Word Tokenization

The next step in our pipeline is to break this sentence into separate words or tokens. 

Step 3: Predicting Parts of Speech for Each Token
Next, we’ll look at each token and try to guess its part of speech?—?whether it is a noun, a verb, an adjective and so on. 
Knowing the role of each word in the sentence will help us start to figure out what the sentence is talking about.
We can do this by feeding each word (and some extra words around it for context) into a pre-trained part-of-speech classification model.
The part-of-speech model was originally trained by feeding it millions of English sentences with each word’s part of speech already 
tagged and having it learn to replicate that behavior.

Keep in mind that the model is completely based on statistics?—?it doesn’t actually understand what the words mean in the same way that humans do. 
It just knows how to guess a part of speech based on similar sentences and words it has seen before.

Step 4: Text Lemmatization
In NLP, we call finding this process lemmatization?—?figuring out the most basic form or lemma of each word in the sentence.

Step 5: Identifying Stop Words
Some NLP pipelines will flag them as stop words —that is, words that you might want to filter out before doing any statistical analysis.

Step 6: Dependency Parsing
The next step is to figure out how all the words in our sentence relate to each other. This is called dependency parsing.

The goal is to build a tree that assigns a single parent word to each word in the sentence.
This parse tree shows us that the subject of the sentence is the noun “London” and it has a “be” relationship with “capital”. We finally know something useful?—?
London is a capital! And if we followed the complete parse tree for the sentence (beyond what is shown), we would even found out that London is the capital of 
the United Kingdom.

Step 6b: Finding Noun Phrases
So far, we’ve treated every word in our sentence as a separate entity. But sometimes it makes more sense to group together the words that represent a single idea 
or thing. We can use the information from the dependency parse tree to automatically group together words that are all talking about the same thing.


Step 7: Named Entity Recognition (NER)
Some of these nouns present real things in the world. For example, “London”, “England” and “United Kingdom” represent physical places on a map. It would be 
nice to be able to detect that! With that information, we could automatically extract a list of real-world places mentioned in a document using NLP.
But NER systems aren’t just doing a simple dictionary lookup. Instead, they are using the context of how a word appears in the sentence and a statistical model 
to guess which type of noun a word represents. A good NER system can tell the difference between “Brooklyn Decker” the person and the place “Brooklyn” using context 
clues.
The goal of Named Entity Recognition, or NER, is to detect and label these nouns with the real-world concepts that they represent.
Here are just some of the kinds of objects that a typical NER system can tag:

People’s names
Company names
Geographic locations (Both physical and political)
Product names
Dates and times
Amounts of money
Names of events

Step 8: Coreference Resolution
At this point, we already have a useful representation of our sentence. We know the parts of speech for each word, how the words relate to each other and which 
words are talking about named entities.

Let’s look at the third sentence in our document:
“It was founded by the Romans, who named it Londinium.” what it refer to ?
The goal of coreference resolution is to figure out this same mapping by tracking pronouns across sentences. We want to figure out all the words that are 
referring to the same entity.

With coreference information combined with the parse tree and named entity information, we should be able to extract a lot of information out of this document!



























